{"name":"ForBES","tagline":"Generic and efficient MATLAB solver for nonsmooth convex optimization problems","body":"**ForBES** (standing for **For**ward-**B**ackward **E**nvelope **S**olver) is a MATLAB solver for\r\nnonsmooth convex optimization problems.\r\n\r\nIt is generic in the sense that the user can customize the problem to solve in an easy and flexible way.\r\nIt is efficient since it features very efficient algorithms, suited for large scale applications.\r\n\r\nHere is a performance comparison between ForBES, the fast forward-backward splitting method (also\r\nknown as fast proximal gradient method) and ADMM (alternating direction method of multipliers),\r\napplied to a Lasso problem with 3K observations and 500K features, for a total of 7.5M nonzero coefficients.\r\n<p align=\"center\">\r\n<img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/lasso_random_3e3_5e5_lambda_3e-1_transparent.png\"\r\n width=\"640\" height=\"404\">\r\n</p>\r\n\r\n## Installation\r\n\r\nSimply clone the git repository, or click on this [link](https://github.com/lostella/ForBES/archive/master.zip)\r\nto download it as a zip archive and decompress the archive. Then move with the MATLAB command line to\r\nthe directory of ForBES. Compile all the *mex*-files required by simply hitting\r\n\r\n```\r\n> make\r\n```\r\n\r\n## How to use it\r\n\r\nForBES consists mainly of two MATLAB routines, `minfbe` and `miname`.\r\nIn order to use them one must provide a description of the problem in a MATLAB\r\nstructure and (optionally) a set of options:\r\n\r\n```\r\nout = minfbe(prob, opt);\r\nout = miname(prob, opt);\r\n```\r\n\r\nStructure `prob` contains attributes describing the details of the problem, such as objective\r\nterms and constraints, while `opt` describes, e.g., details on the algorithm to use, termination\r\ncriteria, the level of verbosity, and so on. In the following we describe more in detail how to define\r\nthese structures. Output `out` will contain the results of the optimization process.\r\n\r\nExamples on how to use `minfbe` and `miname` can be found in the [tests folder](https://github.com/lostella/ForBES/tree/master/tests). Furthermore, you can access the help file of the solvers directly from MATLAB with\r\n\r\n```\r\n> help minfbe\r\n> help miname\r\n```\r\n\r\n## minfbe (convex composite problems)\r\n\r\nWe consider here problems in the form\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/minfbe_problem.png\" alt=\"Convex composite problem\"></p>\r\n\r\nwhere *f1* is convex quadratic, *l* is a linear term and *f2* is any convex, twice continuously\r\ndifferentiable function with Lipschitz continuous gradient. Any of these terms may be omitted in the\r\nproblem definition, in which case it is assumed to be identically zero.\r\nFunction *g* is a general proper, closed, convex function (possibly nonsmooth).\r\nThis form of includes many practical problems arising in several fields such as optimal\r\ncontrol, data analysis, machine learning, image and signal processing to name a few.\r\n\r\nSince *f1* is quadratic, it is entirely specified by its Hessian and linear parts:\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/quad_fun.png\" alt=\"Quadratic function\"></p>\r\n\r\nThe generic nonlinear term *f2* is described by an appropriate function returning its value and gradient\r\n(in this exact order) at any specified point.\r\nThe gradient may be computed only when the corresponding output argument is requested.\r\nFor example, the logistic function\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/log_loss.png\" alt=\"Logistic function\"></p>\r\n\r\ncan be defined in MATLAB as follows\r\n\r\n```\r\nfunction [fz, gradfz] = LogReg(z)\r\n    pz = 1./(1+exp(-z));\r\n    fz = -sum(log(pz));\r\n    if nargout >= 2\r\n        gradfz = (pz-1);\r\n    end\r\nend\r\n```\r\n\r\nThe nonsmooth term *g(x)* is defined through its proximal mapping and the value of\r\n*g* at the proximal point:\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/prox_definition.png\"></p>\r\n\r\nFor example, if *g(x) = r||x||_1* (the L1-norm) then it is described in MATLAB as the following soft-thresholding\r\nprocedure:\r\n\r\n```\r\nfunction [z, v] = L1Norm(x, gam, r)\r\n    uz = max(0, abs(x)-gam*r);\r\n    if nargout >= 2\r\n        v = r*sum(uz);\r\n    end\r\n    z = sign(x).*uz;\r\nend\r\n```\r\n\r\nIn the following table we summarize the attributes that may be used to define problem (1). Notice that **most of them are optional**.\r\n\r\nAttribute | Type | Mandatory? | Default | What is it\r\n----- | ---- | ---------- | ------- | ----------\r\n`prob.x0` | vector | yes | - | The starting point for the algorithm.\r\n`prob.Q` <br> `prob.q` | matrix (or function) and vector | no | Q = 0 <br> q = 0 | The Hessian and linear parts of the quadratic term *f1*.\r\n`prob.A` <br> `prob.b` | matrix (or function) and vector | no | A = Id <br> b = 0 | The affine mapping with which *f1* is composed.\r\n`prob.AT` | function | yes, if A is defined as a function | - | The function computing the adjoint of A.\r\n`prob.lin` | vector | no | 0 | The linear term *l* in the objective.\r\n`prob.f2` | function | no | the zero function | A procedure returning the value of *f2* (1st output) and its gradient (2nd output) at the specified point. It can optionally return also the Hessian as 3d ouput.\r\n`prob.useHessian` | boolean, integer | no | 0 | A flag indicating whether f2 returns also the Hessian of *f2*.\r\n`prob.C` <br> `prob.d` | matrix or function, vector | no | C = Id <br> d = 0 | The affine mapping with which *f2* is composed.\r\n`prob.CT` | function | yes, if C is defined as a function | - | The function computing the adjoint of C.\r\n`prob.Lf1` | real | no | computed numerically | The 2-norm of matrix A'QA.\r\n`prob.Lf2` | real | no | computed numerically | The Lipschitz constant of the gradient of *f2*.\r\n`prob.normC` | real | no | computed numerically | The 2-norm of matrix C.\r\n`prob.g` | function | yes | - | A procedure that given *x* and *gamma* (in this order) computes the proximal point of *x* (1st output) with respect to *g* and stepsize *gamma*, and the value of *g* at the proximal point (2nd output)\r\n\r\n**Example**: using LogReg and L1Norm defined above, we can test the `minfbe` onto the sparse logistic regression problem\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/log_reg.png\" alt=\"Sparse logistic regression\"></p>\r\n\r\nas follows:\r\n\r\n```\r\nprob.C = diag(sparse(b))*A;\r\nprob.f2 = @(x) LogReg(x);\r\nprob.g = @(x, gam) L1Norm(x,gam,reg);\r\nprob.x0 = zeros(n,1);\r\nout = minfbe(prob);\r\n```\r\n\r\nThe `out` structure will contain the results of the optimization process, including the computed solution\r\nand some additional information like the progress of the algorithm during the iterations.\r\n\r\n## miname (convex separable problems)\r\n\r\nWe consider now problems with linear equality constraints, of the following form:\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/miname_problem.png\" alt=\"Equality constrained convex problem\"></p>\r\n\r\nwith *f1* (if present) is strongly convex and quadratic on its domain, *f2* (if present) is strongly\r\nconvex and twice continuously differentiable in the interior of its domain, while *g* is proper, closed\r\nand convex. Linear operators *A1, A2, B* need to be specified only if the corresponding term in the \r\nobjective is present, and they are of appropriate dimension along with vector *c* in the constraints.\r\n\r\nThe problem is described by specifying the constraint and providing appropriate procedures for computing\r\nthe primal iterates (and the corresponding objective values) given a dual variable. Specifically:\r\n\r\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/lostella/ForBES/master/figures/miname_primal_updates.png\"></p>\r\n\r\nThe following table summarizes the attributes defining problem (2). Again, notice that **many of them are optional**.\r\n\r\nAttribute | Type | Mandatory? | Default | What is it\r\n----- | ---- | ---------- | ------- | ----------\r\n`prob.x1step` | function | no | - | Procedure minimizing *f1(w)- y'w* with respect to *w*, given *y* (since *f1* is quadratic, this procedure computes an affine mapping).\r\n`prob.A1` | matrix or function | yes, if `prob.x1step` is defined | - | Matrix *A1* in the constraint.\r\n`prob.A1T` | function | yes, if `prob.A1` is defined as a function | - | Procedure computing the adjoint of *A1*.\r\n`prob.x2step` | function | no | - | Procedure minimizing *f2(w)- y'w* with respect to *w*, given *y*.\r\n`prob.A2` | matrix or function | yes, if `prob.x2step` is defined | - | Matrix *A2* in the constraint.\r\n`prob.A2T` | function | yes, if `prob.A2` is defined as a function | - | Procedure computing the adjoint of *A2*.\r\n`prob.zsetp` | function | yes | - | Procedure minimizing the augmented Lagrangian with respect to *z* and computing *g(z)*.\r\n`prob.B` | matrix | yes | - | Matrix *B* in the constraint.\r\n`prob.c` | vector | yes | - | The right hand side of the constraint.\r\n\r\n## Options\r\n\r\nOptional settings may be enabled by specifying the correspondent fields in the `opt` structure passed\r\nas second argument to `minfbe` and `miname`.\r\n\r\nAttribute | Type | Default | What is it\r\n----- | ---- | ------- | ----------\r\n`opt.tolOpt` | scalar | 1e-5 | Tolerance on the optimality condition.\r\n`opt.maxit` | integer | 100*n* | Maximum number of iterations.\r\n`opt.method` | string | 'lbfgs' | Algorithm to use for computing descent steps. Can select between: <br> 'sd' (steepest descent) <br> 'lbfgs' (limited memory BFGS) <br>  'cg-desc', 'cg-prp', 'cg-dyhs' (various nonlinear CG algorithms) <br> 'bb' (Barzilai-Borwein).\r\n`opt.variant` | string | 'global' | 'basic': Use the basic algorithm<br> 'global': Use the **global** variant<br> 'fast': Use the **fast** variant\r\n`opt.linesearch` | string | method dependant | Line search strategy to use. Can select between: <br> 'armijo' (default for 'sd') <br> 'nonmonotone-armijo' (default for 'bb') <br> 'hager-zhang' (default for the rest) <br> 'lemarechal' <br> 'fletcher'\r\n\r\n## Credits\r\n\r\nForBES is developed by Lorenzo Stella [`lorenzo.stella-at-imtlucca.it`] and Panos Patrinos [`panagiotis.patrinos-at-imtlucca.it`]. Any feedback, bug report or suggestion for future improvements is more than welcome. We recommend using the [issue tracker](https://github.com/lostella/ForBES/issues) to report bugs.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}